{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "import warnings\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import activation_functions\n",
    "import networks \n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/Activation_Functions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_elu.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_elu.tar...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_leakyrelu.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_leakyrelu.tar...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_relu.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_relu.tar...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_sigmoid.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_sigmoid.tar...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_swish.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_swish.tar...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_tanh.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/FashionMNIST_tanh.tar...\n"
     ]
    }
   ],
   "source": [
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)\n",
    "\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial3/\"\n",
    "# Files to download\n",
    "pretrained_files = [\n",
    "    \"FashionMNIST_elu.config\",\n",
    "    \"FashionMNIST_elu.tar\",\n",
    "    \"FashionMNIST_leakyrelu.config\",\n",
    "    \"FashionMNIST_leakyrelu.tar\",\n",
    "    \"FashionMNIST_relu.config\",\n",
    "    \"FashionMNIST_relu.tar\",\n",
    "    \"FashionMNIST_sigmoid.config\",\n",
    "    \"FashionMNIST_sigmoid.tar\",\n",
    "    \"FashionMNIST_swish.config\",\n",
    "    \"FashionMNIST_swish.tar\",\n",
    "    \"FashionMNIST_tanh.config\",\n",
    "    \"FashionMNIST_tanh.tar\",\n",
    "]\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\n",
    "                \"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\",\n",
    "                e,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations applied on each image => first make them a tensor, then normalize them in the range -1 to 1\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_dataset = FashionMNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "# Loading the test set\n",
    "test_set = FashionMNIST(root=DATASET_PATH, train=False, transform=transform, download=True)    \n",
    "\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size=1024, shuffle=True, drop_last=False)\n",
    "val_loader = data.DataLoader(val_set, batch_size=1024, shuffle=False, drop_last=False)\n",
    "test_loader = data.DataLoader(test_set, batch_size=1024, shuffle=False, drop_last=False)\n",
    "            \n",
    "act_fn_by_name = {\"sigmoid\": activation_functions.Sigmoid, \n",
    "                  \"tanh\": activation_functions.Tanh, \n",
    "                  \"relu\": activation_functions.ReLU, \n",
    "                  \"leakyrelu\": activation_functions.LeakyReLU, \n",
    "                  \"elu\": activation_functions.ELU, \n",
    "                  \"swish\": activation_functions.Swish, \n",
    "                  \"tanhelu\": activation_functions.TanhELU, \n",
    "                  \"tanhrelu\": activation_functions.TanhReLU\n",
    "                  }            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseNetwork with sigmoid activation...\n",
      "Model file already exists. Skipping training...\n",
      "============= Test accuracy: 10.00% ==============\n",
      "\n",
      "Training BaseNetwork with tanh activation...\n",
      "Model file already exists. Skipping training...\n",
      "============= Test accuracy: 87.59% ==============\n",
      "\n",
      "Training BaseNetwork with relu activation...\n",
      "Model file already exists. Skipping training...\n",
      "============= Test accuracy: 88.62% ==============\n",
      "\n",
      "Training BaseNetwork with leakyrelu activation...\n",
      "Model file already exists. Skipping training...\n",
      "============= Test accuracy: 88.92% ==============\n",
      "\n",
      "Training BaseNetwork with elu activation...\n",
      "Model file already exists. Skipping training...\n",
      "============= Test accuracy: 87.27% ==============\n",
      "\n",
      "Training BaseNetwork with swish activation...\n",
      "Model file already exists. Skipping training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 2/195 [00:00<00:11, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Test accuracy: 88.73% ==============\n",
      "\n",
      "Training BaseNetwork with tanhelu activation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   1%|          | 2/195 [00:00<00:09, 19.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "\t   (New best performance, saving model...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "\t   (New best performance, saving model...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 2/195 [00:00<00:09, 19.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Test accuracy: 82.06% ==============\n",
      "\n",
      "Training BaseNetwork with tanhrelu activation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   2%|▏         | 3/195 [00:00<00:08, 21.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "\t   (New best performance, saving model...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "\t   (New best performance, saving model...)\n",
      "============= Test accuracy: 81.86% ==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for act_fn_name in act_fn_by_name:\n",
    "    print(f\"Training BaseNetwork with {act_fn_name} activation...\")\n",
    "    utils.set_seed(42)\n",
    "    act_fn = act_fn_by_name[act_fn_name]()\n",
    "    net_actfn = networks.BaseNetwork(act_fn=act_fn).to(device)\n",
    "    utils.train_model(net_actfn, f\"FashionMNIST_{act_fn_name}\",train_set, max_epochs=2,\n",
    "                      overwrite=False, device = device, \n",
    "                      test_loader = test_loader, val_loader = val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
